{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Autom√°tico de Sentimento\n",
    "\n",
    "Voc√™ foi contratado por uma empresa parar analisar como os clientes est√£o reagindo a um determinado produto no Twitter. A empresa deseja que voc√™ crie um programa que ir√° analisar as mensagens dispon√≠veis e classificar√° como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mere√ßam destaque, disparem um foco de aten√ß√£o da √°rea de marketing.<br /><br />\n",
    "Como aluno de Ci√™ncia dos Dados, voc√™ lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que √© largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conte√∫do.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, voc√™ precisa implementar uma vers√£o do classificador que \"aprende\" o que √© relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Ap√≥s validado, o seu prot√≥tipo poder√° tamb√©m capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informa√ß√µes do Projeto\n",
    "\n",
    "Prazo: 19/Set at√© √†s 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas ter√° uma rubrica diferenciada.<br /><br />\n",
    "Entreg√°veis via GitHub: \n",
    "* Arquivo notebook com o c√≥digo do classificador, seguindo as orienta√ß√µes abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**N√ÉO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermedi√°ria: Check 1 - APS 2\n",
    "\n",
    "At√© o dia 10/Set √†s 23:59, xlsx deve estar no Github com as seguintes evid√™ncias: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes j√° classificadas.\n",
    "\n",
    "Sugest√£o de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupo: ##\n",
    "Enrico Aloisi Nardi\n",
    "\n",
    "Evandro Romeiro Fontana\n",
    "\n",
    "Jadson da Silva Oliveira de Jesus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. N√£o se esque√ßa de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. N√£o remover emojis.<br />\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o.\n",
    "\n",
    "Escreva o seu c√≥digo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrindo o arquivo excel\n",
    "\n",
    "planilha = pd.ExcelFile(\"tweets_Nintendo_201809042125.xlsx\")\n",
    "dados= pd.read_excel(planilha,'Treinamento') #'dados' e 'dados2': s√©ries originais vindas diretamente do excel\n",
    "dados2 = pd.read_excel(planilha,'Teste')\n",
    "\n",
    "#Excluindo colunas do excel que n√£o ser√£o utilizadas\n",
    "dados_R = dados.drop(['Classifica√ß√£o (R I)','Classifica√ß√£o (B M)'], axis=1)\n",
    "dados_teste = dados2.drop(['Classifica√ß√£o (R I)','Classifica√ß√£o (B M)'], axis=1)\n",
    "\n",
    "#Fun√ß√£o que limpa a base de dados.. ela recebe a base (dataframe) e o tipo (treinamento ou teste) da base (string) como argumentos\n",
    "def limpa_base(base, tipo):\n",
    "    #Criando listas e dicion√°rios para guardar os dados processados\n",
    "    dados_limpos = {}\n",
    "    frases = []\n",
    "    classi = []\n",
    "    \n",
    "    #Criando as chaves e atribuindo os valores associados as frases e suas respectivas classifica√ß√µes. \n",
    "    dados_limpos[tipo] = frases\n",
    "    dados_limpos[\"Classificacao\"] = classi\n",
    "    varios_emojis = re.compile(r'\\d+(.*?)(?:\\u263a|\\U0001f645)')\n",
    "\n",
    "    #Limpando a base de dados -ou seja, excluindo links de v√≠deos, rt's e @'s-\n",
    "    for i in range(len(base[tipo])):     \n",
    "        Tweet = base.iloc[i][tipo]\n",
    "        apaga_tudo = re.sub('https://[^\\s]+',' ',Tweet)\n",
    "        apaga_tudo = re.sub('@[^\\s]+',' ',apaga_tudo)\n",
    "        apaga_tudo = re.sub('^rt',' ',apaga_tudo)\n",
    "        apaga_tudo = re.sub('[^A-Za-z √£√°√¢√µ√≥√¥√™√©√≠√ßüëô\"u\"\\U0001F600-\\U0001F64F\"u\"\\U0001F300-\\U0001F5FF\"u\"\\U0001F680-\\U0001F6FF\"u\"\\U0001F1E0-\\U0001F1FF\"]',' ',apaga_tudo)\n",
    "        apaga_tudo = re.sub(r'\\b\\w{1,2}\\b ',' ',apaga_tudo)\n",
    "        apaga_tudo = re.sub(r'\\b\\n\\b',' ',apaga_tudo)\n",
    "        apaga_tudo = re.sub(r'\\bque\\b',' ',apaga_tudo)\n",
    "        apaga_tudo = re.sub(r'\\buma\\b',' ',apaga_tudo)\n",
    "        apaga_tudo = re.sub(r'\\bpra\\b',' ',apaga_tudo)\n",
    "        apaga_tudo = re.sub('    ',' ',apaga_tudo)\n",
    "        apaga_tudo = re.sub('   ',' ',apaga_tudo)\n",
    "        apaga_tudo = apaga_tudo.lower()\n",
    "        frases.append(apaga_tudo)\n",
    "        classi.append(base.iloc[i]['Classifica√ß√£o por Subtopicos (MR, R, N, I, MI)'])\n",
    "    return dados_limpos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Limpando os dados da base\n",
    "dados_limpos=limpa_base(dados_R, 'Treinamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 0.13666666666666666,\n",
       " 'MI': 0.1,\n",
       " 'MR': 0.2,\n",
       " 'N': 0.15666666666666668,\n",
       " 'R': 0.4066666666666667}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculando a probabilidade de cada categoria P(MR)\n",
    "\n",
    "dados=pd.DataFrame.from_dict(dados_limpos)\n",
    "\n",
    "total_msgs= len(dados.Classificacao)\n",
    "\n",
    "frequencias = dados.Classificacao.value_counts()\n",
    "\n",
    "#Dicion√°rio com as probabilidades de cada categoria\n",
    "prob_cat={}\n",
    "\n",
    "prob_cat['MR']= frequencias.MR/total_msgs\n",
    "\n",
    "prob_cat['R']= frequencias.R/total_msgs\n",
    "\n",
    "prob_cat['N']= frequencias.N/total_msgs\n",
    "\n",
    "prob_cat['I']= frequencias.I/total_msgs\n",
    "\n",
    "prob_cat['MI']= frequencias.MI/total_msgs\n",
    "prob_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria√ß√£o de um dicion√°rio que cont√™m a contagem das palavras dada uma determinada classe\n",
    "d_base={}\n",
    "d_base['MR']=[]\n",
    "d_base['R']=[]\n",
    "d_base['N']=[]\n",
    "d_base['I']=[]\n",
    "d_base['MI']=[]\n",
    "\n",
    "#Separando o nosso dicion√°rio limpo em duas listas para ent√£o coloca-los no novo dicion√°rio\n",
    "\n",
    "categorias = dados_limpos[\"Classificacao\"]\n",
    "frases = dados_limpos[\"Treinamento\"]\n",
    "\n",
    "todas_palavras = [] #lista de todas as palavras\n",
    "todas_palavras_sr = [] #lista de todas as palavras sem repeti√ß√£o\n",
    "\n",
    "#Percorrendo as listas 'categorias' e 'frases' para criar o dicion√°rio correspondente a cada classifica√ß√£o (MR, R, N, I, MI)\n",
    "for i in range(len(frases)):\n",
    "    lista = frases[i].split() #lista com todas as palavras\n",
    "    todas_palavras.extend(lista)\n",
    "    for e in lista:\n",
    "        if e not in todas_palavras_sr:\n",
    "            todas_palavras_sr.append(e)\n",
    "    \n",
    "    if categorias[i]=='MR': #testando se uma palavras numa posi√ß√£o i (0,1,2...) √© de uma categoria \n",
    "        palavras=frases[i].split()\n",
    "        d_base['MR'].extend(palavras)\n",
    "        \n",
    "    if categorias[i]=='R':\n",
    "        palavras=frases[i].split()\n",
    "        d_base['R'].extend(palavras)\n",
    "        \n",
    "    if categorias[i]=='N':\n",
    "        palavras=frases[i].split()\n",
    "        d_base['N'].extend(palavras)\n",
    "        \n",
    "    if categorias[i]=='I':\n",
    "        palavras=frases[i].split()\n",
    "        d_base['I'].extend(palavras)\n",
    "        \n",
    "    if categorias[i]=='MI':\n",
    "        palavras=frases[i].split()\n",
    "        d_base['MI'].extend(palavras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Conta quantas palavras tem em cada categoria\n",
    "\n",
    "def contadora(dic,categoria): #Recebemos o dicion√°rio que tem as palavras em suas respectivas categorias {'MR':{palavras},'R':{palavras} etc}\n",
    "    MR_l={}\n",
    "    for palavra in dic[categoria]:\n",
    "        if palavra not in MR_l: #Caso ainda n√£o exista a palavra, criamos e atribuimos o valor de 1\n",
    "            MR_l[palavra]= 1\n",
    "        else: #Caso exista adicionamos +1 ao valor existente\n",
    "            MR_l[palavra]+=1\n",
    "    return(MR_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_geral = {}\n",
    "cont_geral[\"MR\"] = contadora(d_base,\"MR\")\n",
    "cont_geral[\"R\"]  = contadora(d_base,\"R\")\n",
    "cont_geral[\"N\"]  = contadora(d_base,\"N\")\n",
    "cont_geral[\"I\"]  = contadora(d_base,\"I\")\n",
    "cont_geral[\"MI\"] = contadora(d_base,\"MI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fun√ß√£o c√°lcula da probabilidade de que uma dada palavra seja de uma determinada classifica√ß√£o (precisamos dividir pela soma\n",
    "#de todas as palavras de uma classifica√ß√£o com as palavras que nao repetem {P(palavra|MR))}\n",
    "\n",
    "def calcula_prob_dado_algo(serie):\n",
    "    prob_algo={}\n",
    "    for k,v in serie.items():\n",
    "        prob_algo[k] = (v+1)/(len(serie) + len(todas_palavras_sr))\n",
    "    return prob_algo\n",
    "\n",
    "dic_prob_palavras_por_cat = {}\n",
    "\n",
    "dic_prob_palavras_por_cat['MR']= calcula_prob_dado_algo(cont_geral[\"MR\"])\n",
    "dic_prob_palavras_por_cat['R']= calcula_prob_dado_algo(cont_geral[\"R\"])\n",
    "dic_prob_palavras_por_cat['N']= prob_pal_N= calcula_prob_dado_algo(cont_geral[\"N\"])\n",
    "dic_prob_palavras_por_cat['I']= calcula_prob_dado_algo(cont_geral[\"I\"])\n",
    "dic_prob_palavras_por_cat['MI']= calcula_prob_dado_algo(cont_geral[\"MI\"])\n",
    "\n",
    "#cont_geral[\"MR\"]\n",
    "\n",
    "#dic_prob_palavras_por_cat['MR'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "#Fun√ß√£o para classificacao de relevancia de uma frase qualquer \n",
    "  \n",
    "def classifica_relevancia(dataframe, probabilidades_categorias, probabilidade_palavras, tipo):\n",
    "    i = 0\n",
    "    frases_limpas = limpa_base(dataframe, tipo)\n",
    "    dic_probabilidade_cada_frase = {}\n",
    "    \n",
    "    for frases in frases_limpas[tipo]:\n",
    "        \n",
    "        lista_palavras_msg = frases.split()\n",
    "        lista_categorias = ['MR','R','N','I','MI']\n",
    "        dic_prob_para_categoria = {}\n",
    "        \n",
    "        for categoria in lista_categorias:\n",
    "            prob_frase = 1\n",
    "            for palavra in lista_palavras_msg:\n",
    "                \n",
    "                if palavra in probabilidade_palavras[categoria]:\n",
    "                    prob_frase *= (probabilidade_palavras[categoria][palavra])\n",
    "                \n",
    "            dic_prob_para_categoria[categoria] = prob_frase*probabilidades_categorias[categoria]\n",
    "        \n",
    "        \n",
    "        dic_probabilidade_cada_frase[i] = dic_prob_para_categoria\n",
    "        i+=1    \n",
    "    return dic_probabilidade_cada_frase\n",
    "  \n",
    "j = classifica_relevancia(dados_teste,prob_cat ,dic_prob_palavras_por_cat, 'Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escolhe_class(frases_classificadas):\n",
    "    maximo = 1\n",
    "    class_max = str()\n",
    "    dick = {}\n",
    "    for frase,d_classificacao in frases_classificadas.items():\n",
    "        minimo = 1\n",
    "        for classificacao, prob in d_classificacao.items():\n",
    "            if prob < minimo:\n",
    "                minimo = prob\n",
    "                class_max = classificacao\n",
    "        dick[frase] = class_max\n",
    "    return dick\n",
    "\n",
    "dicionario_final= escolhe_class(j)\n",
    "s  = pd.DataFrame(list(dicionario_final.items()))\n",
    "dados_clas_juntos= s.join(dados_teste['Classifica√ß√£o por Subtopicos (MR, R, N, I, MI)'])\n",
    "\n",
    "#w= pd.DataFrame.from_dict(limpa_base(dados_teste, 'Teste'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Voc√™ deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas n√£o s√£o relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e s√£o relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como n√£o relevante e n√£o s√£o relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como n√£o relevante e s√£o relevantes)\n",
    "\n",
    "Obrigat√≥rio para grupos de 3 alunos:\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseado na diferen√ßa de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.425\n",
      "0.575\n"
     ]
    }
   ],
   "source": [
    "nossos_valores= dados_clas_juntos[1]\n",
    "\n",
    "valores_teste= dados_clas_juntos['Classifica√ß√£o por Subtopicos (MR, R, N, I, MI)']\n",
    "\n",
    "\n",
    "positivos=0\n",
    "\n",
    "negativos=0\n",
    "\n",
    "for e in range(len(nossos_valores)):\n",
    "    if nossos_valores[e] == valores_teste[e]:\n",
    "        positivos+=1\n",
    "    else:\n",
    "        negativos+=1\n",
    "\n",
    "print(positivos/200)\n",
    "print(negativos/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclus√£o.<br /> \n",
    "Fa√ßa um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como s√£o tratadas as mensagens com dupla nega√ß√£o e sarcasmo.<br />\n",
    "Proponha um plano de expans√£o. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que n√£o posso alimentar minha base de Treinamento automaticamente usando o pr√≥prio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cen√°rios de uso para o classificador Naive-Bayes. Cen√°rios sem intersec√ß√£o com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indica√ß√µes concretas de como implementar (n√£o √© preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Ao considerar que temos 5 classifica√ß√µes diferentes para os tweets das nossas bases de dados, podemos concluir que se as classifica√ß√µes fossem atribu√≠das aleatoriamente a cada um dos tweets, ter√≠amos 20% de chance de acertar a nossa escolha. Sendo assim, podemos dizer que o nosso classificador possui uma efici√™ncia razo√°vel, pois acerta 42,5% das suas proposi√ß√µes baseadas na nossa limpeza da base de dados e nas classifica√ß√µes que atribu√≠mos aos tweets no momento de treinar o classificador.\n",
    "   \n",
    "   Sobre poss√≠veis melhorias para o projeto, √© poss√≠vel dizer que quanto maior a base de treino e quanto menos repeti√ß√µes ela contiver, maiores s√£o as chances de conseguirmos um maior parcentual de acerto uma vez que os dicion√°rios das palavras dado uma categoria se tornaria muito mais abrangente, diminuindo o n√∫mero de casos onde a probabilidade √© calculada atrav√©s do suaviza√ß√£o de Laplace.\n",
    "   \n",
    "   Para lidar com mensagens com dupla nega√ß√£o e/ou sarcasmo, os classificadores identificam a exist√™ncia de um emoji ao lado do texto sarc√°stico. Para os humanos isso pode parecer algo √≥bvio ou imediato, por√©m √© necess√°rio avisar ao computador que quando ele se deparar com determinados emojis, ele est√° diante de uma situa√ß√£o sarc√°stica ou de dupla nega√ß√£o.\n",
    "   \n",
    "   Para que a empresa continue financiando o nosso projeto, pensamos em propor uma coleta em tempo real dos tweets, pois assim seria poss√≠vel saber o sentimento instant√¢neo dos usu√°rios a repseito de um produto.   \n",
    "   \n",
    "   No que diz respeito aos outros poss√≠veis usos do classificador Naive-Bayes, s√£o cit√°veis exemplos como classifica√ß√£o inst√¢nea de texto digitado por um usu√°rio a fim de sugerir a melhor substitui√ß√£o dado um hist√≥rico de erros cometidos por outros usu√°rios, que s√£o constantemente aprendidos. Outro exemplo seria o de um monitor de um rob√¥ de transa√ß√µes do mercado financeiro. Nesta segunda idealiza√ß√£o, o classificador calcularia a probabilidade de a decis√£o seguinte ser de compra ou venda estar certa ou errada baseando-se em uma base de acertos ou erros existentes em um hist√≥rico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
