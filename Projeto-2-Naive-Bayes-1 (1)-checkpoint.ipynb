{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupo: ##\n",
    "Enrico Aloisi Nardi\n",
    "\n",
    "Evandro Romeiro Fontana\n",
    "\n",
    "Jadson da Silva Oliveira de Jesus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrindo o arquivo excel\n",
    "\n",
    "planilha = pd.ExcelFile(\"tweets_Nintendo_201809042125.xlsx\")\n",
    "dados= pd.read_excel(planilha, 'Treinamento')\n",
    "dados2 = pd.read_excel(planilha, 'Teste')\n",
    "\n",
    "##dados= pd.read_excel(\"tweets_Nintendo_201809042125.xlsx\")\n",
    "\n",
    "#Excluindo colunas e linhas que não serão utilizadas\n",
    "dados_R= dados.drop(['Classificação (R I)','Classificação (B M)'], axis=1)\n",
    "dados_teste= dados2.drop(['Classificação (R I)','Classificação (B M)'], axis=1)\n",
    "\n",
    "\n",
    "#Criando listas e dicionários para guardar os dados processados\n",
    "dados_limpos = {}\n",
    "frases = []\n",
    "classi = []\n",
    "\n",
    "#Criando as chaves e atribuindo os valores associados as frases e suas respectivas classificações. \n",
    "dados_limpos[\"Treinamento\"] = frases\n",
    "dados_limpos[\"Classificacao\"] = classi\n",
    "\n",
    "#Limpando a base de dados -ou seja, excluindo links de vídeos, rt's e @'s-\n",
    "for i in range(len(dados_R['Treinamento'])):\n",
    "    \n",
    "    Tweet = dados_R.iloc[i]['Treinamento']\n",
    "    apaga_tudo = re.sub('https://[^\\s]+',' ',Tweet)\n",
    "    apaga_tudo = re.sub('@[^\\s]+',' ',apaga_tudo)\n",
    "    apaga_tudo = re.sub('^rt',' ',apaga_tudo)\n",
    "    apaga_tudo = re.sub('[^A-Za-z ãáâõóôêéíç]',' ',apaga_tudo)\n",
    "    apaga_tudo = re.sub(r'\\b\\w{1,2}\\b ',' ',apaga_tudo)\n",
    "    apaga_tudo = re.sub(r'\\bque\\b',' ',apaga_tudo)\n",
    "    apaga_tudo = re.sub(r'\\buma\\b',' ',apaga_tudo)\n",
    "    apaga_tudo = re.sub(r'\\bpra\\b',' ',apaga_tudo)\n",
    "    apaga_tudo = re.sub('   ',' ',apaga_tudo)\n",
    "    frases.append(apaga_tudo)\n",
    "    classi.append(dados_R.iloc[i]['Classificação por Subtopicos (MR, R, N, I, MI)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando a probabilidade de cada categoria P(MR)\n",
    "\n",
    "dados=pd.DataFrame.from_dict(dados_limpos)\n",
    "\n",
    "total_msgs= len(dados.Classificacao)\n",
    "\n",
    "frequencias = dados.Classificacao.value_counts()\n",
    "\n",
    "#Dicionário com as probabilidades de cada categoria\n",
    "prob_cat={}\n",
    "\n",
    "prob_cat['MR']= frequencias.MR/total_msgs\n",
    "\n",
    "prob_cat['R']= frequencias.R/total_msgs\n",
    "\n",
    "prob_cat['N']= frequencias.N/total_msgs\n",
    "\n",
    "prob_cat['I']= frequencias.I/total_msgs\n",
    "\n",
    "prob_cat['MI']= frequencias.MI/total_msgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criação de um dicionário que contêm a contagem das palavras dada uma determinada classe\n",
    "d_base={}\n",
    "d_base['MR']=[]\n",
    "d_base['R']=[]\n",
    "d_base['N']=[]\n",
    "d_base['I']=[]\n",
    "d_base['MI']=[]\n",
    "\n",
    "#Separando o nosso dicionário limpo em duas listas para então coloca-los no novo dicionário\n",
    "\n",
    "categorias=dados_limpos[\"Classificacao\"]\n",
    "frases=dados_limpos[\"Treinamento\"]\n",
    "\n",
    "todas_palavras = [] #lista de todas as palavras\n",
    "todas_palavras_sr = [] #lista de todas as palavras sem repetição\n",
    "\n",
    "\n",
    "#Percorrendo as listas 'categorias' e 'frases' para criar o dicionário correspondente a cada classificação (MR, R, N, I, MI)\n",
    "for i in range(len(frases)):\n",
    "    lista = frases[i].split() #lista com todas as palavras\n",
    "    todas_palavras.extend(lista)\n",
    "    for e in lista:\n",
    "        if e not in todas_palavras_sr:\n",
    "            todas_palavras_sr.append(e)\n",
    "    \n",
    "    if categorias[i]=='MR': #testando se uma palavras numa posição i (0,1,2...) é de uma categoria \n",
    "        palavras=frases[i].split()\n",
    "        d_base['MR'].extend(palavras)\n",
    "        \n",
    "    if categorias[i]=='R':\n",
    "        palavras=frases[i].split()\n",
    "        d_base['R'].extend(palavras)\n",
    "        \n",
    "    if categorias[i]=='N':\n",
    "        palavras=frases[i].split()\n",
    "        d_base['N'].extend(palavras)\n",
    "        \n",
    "    if categorias[i]=='I':\n",
    "        palavras=frases[i].split()\n",
    "        d_base['I'].extend(palavras)\n",
    "        \n",
    "    if categorias[i]=='MI':\n",
    "        palavras=frases[i].split()\n",
    "        d_base['MI'].extend(palavras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Conta quantas palavras tem em cada categoria\n",
    "\n",
    "def contadora(dic,categoria): #Recebemos o dicionário que tem as palavras em suas respectivas categorias {'MR':{palavras},'R':{palavras} etc}\n",
    "#    MR_l={}\n",
    "#    for palavra in dic[categoria]:\n",
    "#        if palavra not in MR_l: #Caso ainda não exista a palavra, criamos e atribuimos o valor de 1\n",
    "#            MR_l[palavra]= 1\n",
    "#        else: #Caso exista adicionamos +1 ao valor existente\n",
    "#            MR_l[palavra]+=1\n",
    "    MR_f = pd.DataFrame({categoria:dic[categoria]})\n",
    "    return(MR_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_MR = contadora(d_base,\"MR\")\n",
    "cont_R = contadora(d_base,\"R\")\n",
    "cont_N = contadora(d_base,\"N\")\n",
    "cont_I = contadora(d_base,\"I\")\n",
    "cont_MI = contadora(d_base,\"MI\")\n",
    "\n",
    "cont_geral = {}\n",
    "cont_geral[\"MR\"] = cont_MR\n",
    "cont_geral[\"R\"] = cont_R\n",
    "cont_geral[\"N\"] = cont_N\n",
    "cont_geral[\"I\"] = cont_I\n",
    "cont_geral[\"MI\"] = cont_MI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função cálcula da probabilidade de que uma dada palavra seja de uma determinada classificação (precisamos dividir pela soma\n",
    "#de todas as palavras de uma classificação com as palavras que nao repetem {P(palavra|MR))}\n",
    "\n",
    "def calcula_prob_dado_algo(serie,categoria):\n",
    "    vc = serie[categoria].value_counts() #data frame com as frequencias das palavras em uma categoria\n",
    "    prob_algo={}\n",
    "    \n",
    "    for k,v in vc.items():\n",
    "        prob_algo[k] = (v+1)/(len(serie) + len(todas_palavras_sr))\n",
    "    return prob_algo\n",
    "\n",
    "prob_pal_MR= calcula_prob_dado_algo(cont_MR,'MR')\n",
    "prob_pal_R= calcula_prob_dado_algo(cont_R,'R')\n",
    "prob_pal_N= calcula_prob_dado_algo(cont_N,'N')\n",
    "prob_pal_I= calcula_prob_dado_algo(cont_I,'I')\n",
    "prob_pal_MI= calcula_prob_dado_algo(cont_MI,'MI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que classifica \n",
    "\n",
    "#Não é trivial\n",
    "\n",
    "def classifica_relevancia()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados= pd.read_excel(\"tweets_Nintendo_201809042125.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
